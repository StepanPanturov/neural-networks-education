{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Сети Колмогорова-Арнольда (KAN)**\n",
        "---\n",
        "## **1. Историческое развитие**\n",
        "\n",
        "Теорему о представлении непрерывных функций нескольких переменных через суперпозиции непрерывных функций одной переменной и сложения, вставшую в основу KAN, сформулировал Андрей Колмогоров в 1957 году. В 1963 году Владимир Арнольд уточнил представление Колмогорова, показав, как именно можно построить функции от одной переменной, тем самым Арнольд придал теореме Колмогорова практическую форму. Именно этот результат стал известен как теорема Колмогорова-Арнольда.\n",
        "\n",
        "Эта теорема, сформулированная в середине XX века, долгое время считалась теоретически значимой, но практически бесполезной из-за сложности реализации и негладкости внутренних функций, значительно усложняющих обучение.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Математические основы**\n",
        "\n",
        "### **2.1 Теорема Колмогорова-Арнольда**\n",
        "\n",
        "Из теоремы Колмогорова-Арнольда следует, что если $f$ — многомерная непрерывная функция в ограниченной области, то $f$ можно записать как конечную композицию непрерывных функций одной переменной и бинарной операции сложения следующим образом: $$f(x_1, \\dots, x_n) = \\sum_{q=1}^{2n+1} \\Phi_q \\left( \\sum_{p=1}^{n} \\phi_{q,p}(x_p) \\right)\n",
        "$$\n",
        "\n",
        "### **2.2 Проблемы теоремы Колмогорова-Арнольда**\n",
        "\n",
        "Теорему до недавнего времени не рассматривали в качестве основы для создания нейронных сетей по двум причинам:\n",
        "\n",
        "1. **Негладкость одномерных функций.**\n",
        "Теорема предполагает разложение многомерной функции на суперпозицию одномерных, но эти одномерные функции могут быть негладкими. Это делает невозможным применение метода обратного распространения ошибки (backpropagation), который требует дифференцируемости функций.\n",
        "\n",
        "2. **Жёсткая фиксация структуры.**\n",
        "В оригинальной теореме архитектура сети строго ограничена: всего два слоя и $2n + 1$ нейронов в скрытом слое (где $n$ — размерность входных данных). Такая структура слишком проста для большинства практических задач и не обладает гибкостью, необходимой для адаптации к сложным данным.\n",
        "\n",
        "### **2.3 Решение проблем теоремы Колмогорова-Арнольда в KAN**\n",
        "\n",
        "1. **B-сплайны.** Вместо произвольных функций KAN используют гладкие B-сплайны для представления активационных функций. Это гарантирует их дифференцируемость и позволяет применять современные методы обучения. Каждая активационная функция имеет вид:\n",
        "\n",
        "$$\n",
        "\\phi(x) = w_b \\cdot b(x) + w_s \\cdot \\mathrm{spline}(x)\n",
        "$$,\n",
        "\n",
        "$b(x)$ - базовая гладкая функция, $\\mathrm{spline}(x)$ - линейная комбинация B-сплайнов:\n",
        "\n",
        "$$\n",
        "\\mathrm{spline}(x) = \\sum_{i} c_i B_i(x)\n",
        "$$\n",
        "\n",
        "2. **Глубокая композиция.** KAN вводят понятие слоя как матрицы функций:\n",
        "\n",
        "$$\n",
        "Φ_l = \\{\\phi_{l,j,i}\\}, \\quad i = 1..n_{in}, \\quad j = 1.n_{out}\n",
        "$$\n",
        "\n",
        "где $\\phi_{l,j,i}$ - обучаемая 1D функция параметризованная сплайном.\n",
        "\n",
        "Выход KAN вычисляется как композиция L таких слоев:\n",
        "\n",
        "$$\n",
        "\\text{KAN}(\\mathbf{x}) = \\left( \\Phi_{L-1} \\circ \\Phi_{L-2} \\circ \\cdots \\circ \\Phi_0 \\right) \\mathbf{x}\n",
        "$$\n",
        "\n",
        "Что также можно нагляднее представить как:\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = \\sum_{i_{L-1}} \\phi_{L-1, i_L, i_{L-1}} \\left(\n",
        "    \\sum_{i_{L-2}} \\cdots \\left(\n",
        "        \\sum_{i_1} \\phi_{1, i_2, i_1} \\left(\n",
        "            \\sum_{i_0} \\phi_{0, i_1, i_0}(x_{i_0})\n",
        "        \\right)\n",
        "    \\right) \\cdots\n",
        "\\right)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Основная структура**\n",
        "\n",
        "\n",
        "### **3.1 Представление слоев**\n",
        "Архитектура задается списком:\n",
        "\n",
        "$$\n",
        "[n_0, n_1, \\dots, n_L]\n",
        "$$\n",
        "\n",
        "где $n_l$ - количество нейронов в слое $l$.\n",
        "\n",
        "### **3.2 Функция активации**\n",
        "Каждая связь между нейронами $(l, i)$ и $(l + 1, j)$ имеет свою функцию активации:\n",
        "\n",
        "$$\n",
        "\\phi_{l,j,i}: ℝ → ℝ\n",
        "$$\n",
        "\n",
        "Параметризованную как:\n",
        "\n",
        "$$\n",
        "\\phi_{l,j,i}(x) = w_b \\cdot b(x) + w_s \\cdot \\mathrm{spline}(x)\n",
        "$$\n",
        "\n",
        "### **3.3 Вычисления в слое**\n",
        "\n",
        "Выход нейрона (в данном случае нейрона $(l +1, j)$) вычисляется как сумма входящих в него функций:\n",
        "\n",
        "$$\n",
        "x_{l+1, j} = \\sum_{i=1}^{n_l}\\phi_{l,j,i}(x_{l, i})\n",
        "$$\n",
        "\n",
        "Если выражать это в матричной форме:\n",
        "\n",
        "$$\n",
        "x_{l+1} = Φ_lx_l\n",
        "$$\n",
        "\n",
        "где - функциональная матрица:\n",
        "\n",
        "$$\n",
        "\\Phi_l =\n",
        "\\begin{bmatrix}\n",
        "\\phi_{l,1,1} & \\cdots & \\phi_{l,1,n_l} \\\\\n",
        "\\vdots & \\ddots & \\vdots \\\\\n",
        "\\phi_{l,n_{l+1},1} & \\cdots & \\phi_{l,n_{l+1},n_l}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "### **3.4 Полная сеть**\n",
        "\n",
        "Полная сеть уже была описана выше и выглядит следующим образом:\n",
        "\n",
        "$$\n",
        "\\text{KAN}(\\mathbf{x}) = \\left( \\Phi_{L-1} \\circ \\Phi_{L-2} \\circ \\cdots \\circ \\Phi_0 \\right) \\mathbf{x}\n",
        "$$\n",
        "\n",
        "Или в другой форме:\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = \\sum_{i_{L-1}} \\phi_{L-1, i_L, i_{L-1}} \\left(\n",
        "    \\sum_{i_{L-2}} \\cdots \\left(\n",
        "        \\sum_{i_1} \\phi_{1, i_2, i_1} \\left(\n",
        "            \\sum_{i_0} \\phi_{0, i_1, i_0}(x_{i_0})\n",
        "        \\right)\n",
        "    \\right) \\cdots\n",
        "\\right)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 4. **Сравнение KAN с MLP**\n",
        "\n",
        "Многослойные перцептроны долгое время остаются стандартом для аппроксимации нелинейных функций в глубоком обучении. Благодаря универсальной теореме аппроксимации и простоте реализации, MLP легли в основу практически всех современных нейросетевых архитектур.\n",
        "\n",
        "### 4.1 **Функции активации**\n",
        "- **MLP**: Нелинейные функции активации (ReLU, tanh, сигмоида и т.д.) одинаковые для всего слоя, расположены на узлах.\n",
        "- **KAN**: \tОбучаемые нелинейные B-сплайны разные для каждого входа, расположены на ребрах.\n",
        "\n",
        "### 4.2 **Параметризация**\n",
        "- **MLP**:\n",
        "  - Линейные веса: $W \\in \\mathbb{R}^{n_{l+1} \\times n_l}$\n",
        "  - Фиксированные активации: $\\sigma(Wx + b)$\n",
        "- **KAN**:\n",
        "  - Обучаемые функции: $\\phi_{l,j,i}(x) = w_b b(x) + w_s \\text{spline}(x)$\n",
        "  - Нет линейных весов - только параметры сплайнов\n",
        "\n",
        "### 4.3 **Стратегия аппроксимации**\n",
        "\n",
        "* **MLP**: Глобальная аппроксимация — каждый нейрон участвует в формировании всего выходного пространства, обучение распределяет информацию по всей сети.\n",
        "* **KAN**: Локальная аппроксимация — B-сплайны действуют в ограниченных интервалах, что позволяет точно аппроксимировать функции с локальными особенностями.\n",
        "\n",
        "### 4.4 **Метод обучения**\n",
        "\n",
        "* **MLP**: Сквозное обучение (end-to-end) методом обратного распространения ошибки (backpropagation).\n",
        "* **KAN**: Также используется backpropagation, благодаря дифференцируемости сплайнов.\n",
        "\n",
        "### 4.5 **Скорость обучения**\n",
        "\n",
        "* **MLP**: Обычно быстрее обучается благодаря простоте операций и хорошо проработанным оптимизаторам.\n",
        "* **KAN**: Медленнее из-за более сложной архитектуры и численно затратных операций со сплайнами.\n",
        "\n",
        "### 4.6 **Размер и вычислительная эффективность**\n",
        "\n",
        "* **MLP**: Требует больше параметров, но оптимален по числу FLOPs (Floating Point Operations).\n",
        "* **KAN**: Для достижения сопоставимой точности требует меньше параметров, но больше вычислений из-за стоимости сплайнов (больше FLOPs на одно соединение).\n",
        "\n",
        "### 4.7 **Интерпретируемость**\n",
        "\n",
        "* **MLP**: Низкая — веса и активации сложно интерпретировать, особенно в глубоких сетях.\n",
        "* **KAN**: Выше — каждая функция на ребре явно задана (например, через B-сплайн), что позволяет анализировать вклад каждого входа в выход.\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Методология обучения KAN**\n",
        "\n",
        "Обучение KAN строится на тех же принципах, что и обучение классических нейросетей, но с рядом особенностей, связанных с обучаемыми функциями активации и нестандартной структурой параметров.\n",
        "\n",
        "### **5.1 Инициализация параметров**\n",
        "\n",
        "Обучение начинается с случайной инициализации параметров сети. В отличие от MLP, где инициализируются веса и смещения, в KAN инициализируются:\n",
        "\n",
        "* коэффициенты B-сплайнов,\n",
        "* весовые коэффициенты линейной составляющей (если используется),\n",
        "\n",
        "### **5.2 Прямой и обратный проход**\n",
        "\n",
        "Процесс обучения включает два этапа:\n",
        "\n",
        "1. **Прямой проход (forward pass)**: входные данные проходят через сеть, на каждом ребре применяются индивидуальные B-сплайны, результат агрегируется и формирует выход модели.\n",
        "2. **Обратный проход (backward pass)**: вычисляется ошибка между предсказанием и истинной меткой, после чего с помощью правила цепочки (chain rule) дифференцирования вычисляются градиенты по всем параметрам.\n",
        "\n",
        "Параметры обновляются с помощью стандартных методов оптимизации, таких как градиентный спуск, стохастический градиентный спуск (SGD), Adam и т.д.\n",
        "\n",
        "### **5.3 Проблемы стабильности и регуляризация**\n",
        "\n",
        "Одной из ключевых сложностей при обучении KAN является обеспечение стабильности и сходимости процесса оптимизации. Это связано с тем, что обучаемые функции активации (B-сплайны) имеют сложную зависимость от параметров и могут вызывать переобучение или нестабильные градиенты.\n",
        "\n",
        "Для решения этих проблем применяются похожие с MLP методы:\n",
        "\n",
        "* **Dropout** — для предотвращения переобучения;\n",
        "* **Weight decay** — для ограничения роста параметров;\n",
        "* **Batch normalization** и **Layer normalization** — для стабилизации распределений активаций и ускорения сходимости.\n",
        "\n",
        "### **5.4 Сквозное обучение**\n",
        "\n",
        "KAN поддерживают сквозное (end-to-end) обучение, при котором все параметры сети обучаются одновременно. Поддержка backpropagation и end-to-end обучения позволяет интегрировать KAN в современные фреймворки глубокого обучения (например, PyTorch), использовать его вместе с другими архитектурными блоками (CNN, Transformer) и обучать модель без ручной настройки отдельных этапов.\n",
        "\n",
        "---\n",
        "\n",
        "## **6. Практические применения**\n",
        "\n",
        "KAN демонстрируют высокую точность и эффективность в ряде задач, где требуется точная аппроксимация, сохранение информации и компактность модели.\n",
        "Далее будут представлены результаты экспериментов из статьи KAN: Kolmogorov–Arnold Networks (https://arxiv.org/pdf/2404.19756).\n",
        "\n",
        "### **6.1 Аппроксимация аналитических и символьных функций**\n",
        "\n",
        "KAN превосходно подходят для символьной регрессии — задачи восстановления математической формулы по точкам. В экспериментах:\n",
        "\n",
        "* KAN с тем же количеством параметров, что и MLP, достигали меньших ошибок на обучении и тесте.\n",
        "* Особенно заметно преимущество при увеличении размерности входов и усложнении функции: глубокие KAN масштабируются лучше, чем глубокие MLP.\n",
        "\n",
        "### **6.2 Приближение специальных функций**\n",
        "\n",
        "KAN эффективно аппроксимируют специальные математические функции, широко используемые в физике и инженерии (например, функции Бесселя, Лежандра и сферические гармоники).\n",
        "\n",
        "* В тесте на 15 таких функций KAN показали устойчиво меньшую ошибку на обучении и тесте, чем MLP, при одинаковом числе параметров.\n",
        "* Компактные структуры KAN обеспечивали точность, сопоставимую с MLP, в которых было в десятки и сотни раз больше параметров.\n",
        "\n",
        "### **6.3 Решение дифференциальных уравнений (PDE)**\n",
        "\n",
        "KAN демонстрируют впечатляющую эффективность в задачах численного решения уравнений в частных производных:\n",
        "\n",
        "* KAN с 2 слоями шириной 10 показали точность $10^{-7}$,\n",
        "* В то время как MLP с 4 слоями шириной 100 достигали только $10^{-5}$,\n",
        "* При этом KAN использовал в 100 раз меньше параметров.\n",
        "\n",
        "### **6.4 Continual Learning**\n",
        "\n",
        "KAN устойчивы к проблеме катастрофического забывания, благодаря своей локальной природе B-сплайнов:\n",
        "\n",
        "* При обучении новому примеру изменяются только локальные участки B-сплайнов.\n",
        "* Остальные части сети остаются нетронутыми — сеть сохраняет ранее выученные знания.\n",
        "* В отличие от MLP, где обновления могут влиять на весь выход, в KAN правки минимальны и изолированы.\n",
        "\n",
        "Это делает их подходящими для задач, где данные приходят поэтапно, как в обучении на потоке данных или в реальных временных системах.\n",
        "\n",
        "### **6.5 Компактные модели для сложных задач**\n",
        "\n",
        "Как уже было представлено в экспериментах выше, KAN больше всего выигрывает в требовательности к числу параметров:\n",
        "\n",
        "* KAN с 200 параметрами достиг 81.6% точности в задаче предсказания геометрического инварианта узлов (knot classification),\n",
        "* В то время как модель от Google DeepMind (MLP с \\~300,000 параметров) — только 78% точности.\n",
        "\n",
        "Это подчёркивает высокую параметрическую эффективность KAN.\n",
        "\n",
        "---\n",
        "\n",
        "## **7. Сильные и слабые стороны**\n",
        "\n",
        "### **7.1 Сильные стороны**\n",
        "\n",
        "- **Высокая выразительная способность**\n",
        "\n",
        "KAN эффективно аппроксимируют сложные математические зависимости и специальные функции даже при малом числе параметров. Их обучаемые B-сплайны позволяют точно передавать локальные особенности функций.\n",
        "\n",
        "- **Параметрическая эффективность**\n",
        "\n",
        "Для достижения той же точности, что и MLP, KAN требует в десятки или сотни раз меньше параметров.\n",
        "\n",
        "- **Интерпретируемость**\n",
        "\n",
        "Каждая связь в KAN представлена явной функцией, что позволяет анализировать, какой именно вход как влияет на выход, в отличие от \"черного ящика\" в MLP.\n",
        "\n",
        "- **Обучение без забывания (continual learning)**\n",
        "\n",
        "Локальная природа сплайнов позволяет KAN сохранять ранее выученные знания, не разрушая их при обучении на новых данных. Это делает модель устойчивой к катастрофическому забыванию.\n",
        "\n",
        "### **7.2 Слабые стороны**\n",
        "\n",
        "- **Сложность обучения**\n",
        "\n",
        "Обучение KAN требует аккуратной настройки: неправильная инициализация, слишком высокий learning rate или плохая структура сплайна могут привести к нестабильности или затуханию градиентов.\n",
        "\n",
        "- **Более высокая вычислительная стоимость (FLOPs)**\n",
        "\n",
        "Хотя число параметров у KAN меньше, число операций (FLOPs) больше, чем у MLP. Это делает KAN медленнее в задачах, где важна скорость, особенно на GPU.\n",
        "\n",
        "- **Недостаток фреймворков и библиотек**\n",
        "\n",
        "KAN пока не так широко распространены, как MLP. Поддержка во фреймворках ограничена, а автоматический подбор архитектур и оптимизация только развивается.\n",
        "\n",
        "- **Недостаток практических исследований**\n",
        "\n",
        "По сетям Колмогорова-Арнольда на данный момент мало исследований, при этом некоторые из них противоречат друг другу в результатах экспериментов. К примеру, в оригинальной статье [1] в плюс KAN ставится continual learning и устойчивость к забыванию, но в более поздней статье [2] указывается на то, что в таких задачах как, например, CV, KAN в contunual learning наоборот проявляет себя хуже, чем MLP.\n",
        "\n",
        "---\n",
        "\n",
        "## **8. Перспективы развития KAN**\n",
        "\n",
        "Сети Колмогорова-Арнольда стали активно развивать в 2024 году, после публикации статьи [1], в которой были преодолены основные проблемы из пункта 2.2. В данный момент исследований на эту тему недостаточно, но уже можно выделить основные векторы развития и проблемы, которые нужно будет решить.\n",
        "\n",
        "### **8.1 Расширение прикладных областей**\n",
        "\n",
        "Хотя KAN показали отличные результаты в задачах аппроксимации аналитических функций, символьной регрессии и решения уравнений в частных производных, дальнейшее развитие требует их адаптации к более прикладным областям, включая компьютерное зрение, обработку естественного языка и табличные данные. Уже начались попытки встраивания KAN в визуальные архитектуры (например, Vision-KAN [3] и U-KAN [4]).\n",
        "\n",
        "### **8.2 Совершенствование обучения**\n",
        "\n",
        "Одним из препятствий для широкого применения KAN остаются сложности в обучении: высокая вычислительная стоимость и нестабильность градиентов. Перспективным направлением является развитие более устойчивых оптимизационных подходов, включая гибридные схемы (например, чередование Adam и LBFGS, предложенное в [1]) и автоматическую настройку структуры сплайнов.\n",
        "\n",
        "Также может быть полезным использование техник из области нейроэволюции или нейроархитектурного поиска (NAS) для автоматического подбора формы KAN и оптимального распределения контрольных точек.\n",
        "\n",
        "### **8.3 Интерпретируемость и научные применения**\n",
        "\n",
        "KAN демонстрируют потенциал как инструмент объяснимого машинного обучения (XAI). Возможность анализировать каждую обученную функцию на ребре делает KAN привлекательными для приложений в науке и инженерии, где важно понимать, как модель пришла к выводу. Исследования компактных представлений специальных функций открывают возможности для использования KAN как инструмента автоматического поиска символических выражений или даже новых математических закономерностей.\n",
        "\n",
        "---\n",
        "\n",
        "## Заключение\n",
        "\n",
        "Сети Колмогорова-Арнольда представляют собой перспективную архитектуру, сочетающую в себе гибкость, интерпретируемость и высокую точность аппроксимации. Использование обучаемых B-сплайнов на уровне соединений позволяет KAN уже превосходить классические MLP в некоторых задачах. Однако сети Колмогорова-Арнольда имеют много весомых недостатков, более того, несмотря на успехи первых работ, теоретическая база и практический опыт пока очень ограничены — многие заявленные преимущества нуждаются в подтверждении в более широком спектре прикладных задач и при использовании современных методов обучения. Тем не менее, потенциал KAN очевиден.\n",
        "\n",
        "## **Источники**\n",
        "\n",
        "[1] Liu, Z. (2024). Kolmogorov–Arnold Networks (KANs). arXiv:2404.19756\n",
        "\n",
        "[2] Runpeng Yu, Weihao Yu, and Xinchao Wang (2024). KAN or MLP: A Fairer Comparison. arXiv:2407.16674\n",
        "\n",
        "[3] Chenziwen Haoshuai. (2024). Vision-KAN. GitHub repository. https://github.com/chenziwenhaoshuai/Vision-KAN\n",
        "\n",
        "[4] Gu, W., Wang, X., & Yu, R. (2024). U-KAN makes strong backbone for medical image segmentation and generation. arXiv preprint, arXiv:2406.02918"
      ],
      "metadata": {
        "id": "ATjuiqs43DbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.datasets import make_friedman2, make_circles, make_friedman3"
      ],
      "metadata": {
        "id": "Sw6tcc7pk54t"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KANNetwork(nn.Module):\n",
        "    def __init__(self, n_neurons=5, num_control_points=20, degree=2, input_dim=1, output_dim=1, max_epochs=100, animation_interval=5):\n",
        "        super(KANNetwork, self).__init__()\n",
        "        self.n_neurons = n_neurons\n",
        "        self.num_control_points = num_control_points\n",
        "        self.degree = degree\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.max_epochs = max_epochs\n",
        "        self.animation_interval = animation_interval\n",
        "        self.scaler = StandardScaler()\n",
        "        self.training_history = []\n",
        "\n",
        "        self.knot_range = (-1, 1)\n",
        "        self.splines = nn.ModuleList([\n",
        "            self.BSpline(num_control_points, degree, self.knot_range) for _ in range(n_neurons)\n",
        "        ])\n",
        "        self.linear = nn.Linear(n_neurons * input_dim, output_dim)\n",
        "\n",
        "    class BSpline(nn.Module):\n",
        "        def __init__(self, num_control_points=20, degree=2, knot_range=(-1, 1)):\n",
        "            super().__init__()\n",
        "            self.num_control_points = num_control_points\n",
        "            self.degree = degree\n",
        "            self.control_points = nn.Parameter(torch.randn(num_control_points))\n",
        "            knots = torch.linspace(knot_range[0], knot_range[1], num_control_points + degree + 1)\n",
        "            self.register_buffer('knots', knots)\n",
        "\n",
        "        def basis_function(self, x, knot_idx, degree):\n",
        "            if degree == 0:\n",
        "                return ((self.knots[knot_idx] <= x) & (x < self.knots[knot_idx + 1])).float()\n",
        "            denom_left = self.knots[knot_idx + degree] - self.knots[knot_idx]\n",
        "            denom_right = self.knots[knot_idx + degree + 1] - self.knots[knot_idx + 1]\n",
        "            if denom_left < 1e-10:\n",
        "                left = torch.zeros_like(x)\n",
        "            else:\n",
        "                left = (x - self.knots[knot_idx]) / denom_left\n",
        "            if denom_right < 1e-10:\n",
        "                right = torch.zeros_like(x)\n",
        "            else:\n",
        "                right = (self.knots[knot_idx + degree + 1] - x) / denom_right\n",
        "            return (left.clamp(0, 1) * self.basis_function(x, knot_idx, degree - 1) +\n",
        "                    right.clamp(0, 1) * self.basis_function(x, knot_idx + 1, degree - 1))\n",
        "\n",
        "        def forward(self, x):\n",
        "            result = torch.zeros_like(x)\n",
        "            for i in range(self.num_control_points):\n",
        "                basis_val = self.basis_function(x, i, self.degree)\n",
        "                result += self.control_points[i] * basis_val\n",
        "            mask_left = x < self.knots[0]\n",
        "            mask_right = x > self.knots[-1]\n",
        "            if mask_left.any():\n",
        "                result[mask_left] = self.control_points[0] * self.basis_function(x[mask_left], 0, self.degree)\n",
        "            if mask_right.any():\n",
        "                result[mask_right] = self.control_points[-1] * self.basis_function(x[mask_right], self.num_control_points - 1, self.degree)\n",
        "            return result\n",
        "\n",
        "    def forward(self, x):\n",
        "        if isinstance(x, np.ndarray):\n",
        "            x = torch.tensor(self.scaler.transform(x), dtype=torch.float32)\n",
        "        activations = []\n",
        "        for i in range(self.input_dim):\n",
        "            x_i = x[:, i]\n",
        "            spline_outputs = torch.stack([spline(x_i) for spline in self.splines], dim=1)\n",
        "            activations.append(spline_outputs)\n",
        "        activations = torch.cat(activations, dim=1)\n",
        "        output = self.linear(activations)\n",
        "        return output\n",
        "\n",
        "    def fit(self, X, y, epochs=None, lr=0.01, animate=False, l2_lambda=1e-4):\n",
        "        X_min, X_max = X.min(), X.max()\n",
        "        self.knot_range = (X_min - 0.5, X_max + 0.5)\n",
        "        for spline in self.splines:\n",
        "            spline.knots = torch.linspace(self.knot_range[0], self.knot_range[1],\n",
        "                                        spline.num_control_points + spline.degree + 1)\n",
        "\n",
        "        self.scaler.fit(X)\n",
        "        X_scaled = torch.tensor(self.scaler.transform(X), dtype=torch.float32)\n",
        "        y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "        criterion = nn.MSELoss()\n",
        "        epochs = epochs or self.max_epochs\n",
        "        self.training_history = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            optimizer.zero_grad()\n",
        "            output = self(X_scaled)\n",
        "            loss = criterion(output, y)\n",
        "            l2_reg = 0\n",
        "            for spline in self.splines:\n",
        "                l2_reg += torch.norm(spline.control_points, p=2)\n",
        "            loss += l2_lambda * l2_reg\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if animate and (epoch % self.animation_interval == 0 or epoch == epochs - 1):\n",
        "                with torch.no_grad():\n",
        "                    # Сохраняем предсказания для x_range, а не для X\n",
        "                    x_range = np.linspace(X.min() - 0.5, X.max() + 0.5, 300).reshape(-1, 1)\n",
        "                    x_range_scaled = torch.tensor(self.scaler.transform(x_range), dtype=torch.float32)\n",
        "                    y_pred = self(x_range_scaled).detach().numpy()\n",
        "                    mse = float(loss.item())\n",
        "                    self.training_history.append({\n",
        "                        'epoch': epoch,\n",
        "                        'y_pred': y_pred,  # Предсказания для x_range\n",
        "                        'mse': mse\n",
        "                    })\n",
        "\n",
        "    def predict(self, X):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            X_scaled = torch.tensor(self.scaler.transform(X), dtype=torch.float32)\n",
        "            return self(X_scaled).numpy()\n",
        "\n",
        "    def calculate_metrics(self, y_true, y_pred):\n",
        "        y_true = y_true.flatten()\n",
        "        y_pred = y_pred.flatten()\n",
        "        mse = np.mean((y_true - y_pred) ** 2)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = np.mean(np.abs(y_true - y_pred))\n",
        "        ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "        ss_res = np.sum((y_true - y_pred) ** 2)\n",
        "        r2 = 1 - ss_res / ss_tot if ss_tot != 0 else 0\n",
        "        nrmse = rmse / (y_true.max() - y_true.min()) if y_true.max() != y_true.min() else 0\n",
        "        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100 if not np.any(y_true == 0) else np.inf\n",
        "        mdape = np.median(np.abs((y_true - y_pred) / y_true)) * 100 if not np.any(y_true == 0) else np.inf\n",
        "        max_error = np.max(np.abs(y_true - y_pred))\n",
        "        return {\n",
        "            'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2,\n",
        "            'nrmse': nrmse, 'mape': mape, 'mdape': mdape, 'max_error': max_error\n",
        "        }\n",
        "\n",
        "    def visualize_spline_functions(self, X, feature_names=None, X_train=None, y_train=None):\n",
        "        self.eval()\n",
        "        if feature_names is None:\n",
        "            feature_names = [f'X{i+1}' for i in range(X.shape[1])]\n",
        "\n",
        "        if X.shape[1] == 1:\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            x_range = np.linspace(X.min() - 0.5, X.max() + 0.5, 300).reshape(-1, 1)\n",
        "            x_scaled = torch.tensor(self.scaler.transform(x_range), dtype=torch.float32)\n",
        "\n",
        "            plt.subplot(2, 1, 1)\n",
        "            if X_train is not None and y_train is not None:\n",
        "                plt.scatter(X_train, y_train, alpha=0.6, color='blue', label='Обучающие данные')\n",
        "            with torch.no_grad():\n",
        "                y_pred = self(x_scaled).detach().numpy()\n",
        "            plt.plot(x_range, y_pred, 'r-', linewidth=2, label='Предсказание KAN')\n",
        "            plt.title('Аппроксимация KAN')\n",
        "            plt.xlabel(feature_names[0])\n",
        "            plt.ylabel('Y')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "            plt.subplot(2, 1, 2)\n",
        "            with torch.no_grad():\n",
        "                for i, spline in enumerate(self.splines):\n",
        "                    spline_output = spline(x_scaled[:, 0]).detach().numpy()\n",
        "                    plt.plot(x_range, spline_output, alpha=0.7, label=f'Сплайн {i+1}')\n",
        "            plt.title('B-сплайн функции')\n",
        "            plt.xlabel(feature_names[0])\n",
        "            plt.ylabel('Активация')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        elif X.shape[1] == 2:\n",
        "            fig = plt.figure(figsize=(15, 5))\n",
        "            x1_range = np.linspace(X[:, 0].min() - 0.5, X[:, 0].max() + 0.5, 50)\n",
        "            x2_range = np.linspace(X[:, 1].min() - 0.5, X[:, 1].max() + 0.5, 50)\n",
        "            x1, x2 = np.meshgrid(x1_range, x2_range)\n",
        "            X_grid = np.column_stack([x1.ravel(), x2.ravel()])\n",
        "            x_scaled = torch.tensor(self.scaler.transform(X_grid), dtype=torch.float32)\n",
        "\n",
        "            ax = fig.add_subplot(131, projection='3d')\n",
        "            with torch.no_grad():\n",
        "                y_pred = self(x_scaled).detach().numpy().reshape(x1.shape)\n",
        "            ax.plot_surface(x1, x2, y_pred, cmap='viridis', alpha=0.8)\n",
        "            if X_train is not None and y_train is not None:\n",
        "                ax.scatter(X_train[:, 0], X_train[:, 1], y_train, color='red', label='Обучающие данные')\n",
        "            ax.set_title('Аппроксимация KAN')\n",
        "            ax.set_xlabel(feature_names[0])\n",
        "            ax.set_ylabel(feature_names[1])\n",
        "            ax.set_zlabel('Y')\n",
        "            ax.legend()\n",
        "\n",
        "            for i, spline in enumerate(self.splines[:2]):\n",
        "                ax = fig.add_subplot(132 + i, projection='3d')\n",
        "                with torch.no_grad():\n",
        "                    spline_output = spline(x_scaled[:, 0]).detach().numpy().reshape(x1.shape)\n",
        "                ax.plot_surface(x1, x2, spline_output, cmap='plasma', alpha=0.8)\n",
        "                ax.set_title(f'Сплайн {i+1}')\n",
        "                ax.set_xlabel(feature_names[0])\n",
        "                ax.set_ylabel(feature_names[1])\n",
        "                ax.set_zlabel('Активация')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    def get_spline_outputs(self, X):\n",
        "        self.eval()\n",
        "        X_scaled = torch.tensor(self.scaler.transform(X), dtype=torch.float32)\n",
        "        outputs = []\n",
        "        with torch.no_grad():\n",
        "            for spline in self.splines:\n",
        "                output = spline(X_scaled[:, 0]).detach().numpy()\n",
        "                outputs.append(output)\n",
        "        return outputs\n",
        "\n",
        "    def animate_training(self, X, y, interval=200):\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        x_range = np.linspace(X.min() - 0.5, X.max() + 0.5, 300).reshape(-1, 1)\n",
        "        y_true = y.flatten()\n",
        "        line, = ax.plot([], [], 'r-', label='Предсказание KAN')\n",
        "        ax.scatter(X, y_true, alpha=0.6, color='blue', label='Обучающие данные')\n",
        "        ax.set_xlim(X.min() - 0.5, X.max() + 0.5)\n",
        "        ax.set_ylim(y_true.min() - 0.5, y_true.max() + 0.5)\n",
        "        ax.set_xlabel('X')\n",
        "        ax.set_ylabel('Y')\n",
        "        ax.legend()\n",
        "        ax.grid(True)\n",
        "        text = ax.text(0.05, 0.95, '', transform=ax.transAxes, verticalalignment='top')\n",
        "\n",
        "        def init():\n",
        "            line.set_data([], [])\n",
        "            return line,\n",
        "\n",
        "        def update(frame):\n",
        "            history = self.training_history[frame]\n",
        "            y_pred = history['y_pred'].flatten()  # Предсказания уже для x_range\n",
        "            mse = history['mse']\n",
        "            epoch = history['epoch']\n",
        "            sort_idx = np.argsort(x_range.flatten())\n",
        "            line.set_data(x_range[sort_idx], y_pred[sort_idx])\n",
        "            text.set_text(f'Epoch: {epoch}, MSE: {mse:.6f}')\n",
        "            return line, text\n",
        "\n",
        "        ani = FuncAnimation(fig, update, frames=len(self.training_history),\n",
        "                            init_func=init, blit=True, interval=interval)\n",
        "        return ani"
      ],
      "metadata": {
        "id": "FxY3Kb6F8vmg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_with_kan(X, y, n_neurons_list, n_control_points_list, X_train=None, y_train=None):\n",
        "    \"\"\"\n",
        "    Проводит эксперименты с разными параметрами KAN-сети\n",
        "\n",
        "    Parameters:\n",
        "    - X: Обучающие данные (n_samples, n_features)\n",
        "    - y: Целевые значения (n_samples,)\n",
        "    - n_neurons_list: Список чисел нейронов в скрытом слое\n",
        "    - n_control_points_list: Список чисел контрольных точек для B-сплайнов\n",
        "    - X_train: Тренировочные данные (опционально, для вычисления ошибки)\n",
        "    - y_train: Тренировочные целевые значения (опционально)\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame с результатами экспериментов\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for n_neurons in n_neurons_list:\n",
        "        for n_control_points in n_control_points_list:\n",
        "            # Создаем и обучаем модель\n",
        "            model = KANNetwork(n_neurons=n_neurons, num_control_points=n_control_points, degree=3)\n",
        "            model.fit(X, y)\n",
        "\n",
        "            # Вычисляем ошибки\n",
        "            train_pred = model.predict(X)\n",
        "            train_mse = np.mean((train_pred.flatten() - y.flatten()) ** 2)\n",
        "\n",
        "            result = {\n",
        "                'n_neurons': n_neurons,\n",
        "                'n_control_points': n_control_points,\n",
        "                'train_mse': train_mse\n",
        "            }\n",
        "\n",
        "            # Если есть тренировочные данные\n",
        "            if X_train is not None and y_train is not None:\n",
        "                test_pred = model.predict(X_train)\n",
        "                test_mse = np.mean((test_pred.flatten() - y_train.flatten()) ** 2)\n",
        "                result['test_mse'] = test_mse\n",
        "\n",
        "            results.append(result)\n",
        "\n",
        "    # Создаем DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "    return results_df\n",
        "\n",
        "def visualize_experiment_results(results_df, test_data_available=False):\n",
        "    \"\"\"\n",
        "    Визуализирует результаты экспериментов с KAN\n",
        "\n",
        "    Parameters:\n",
        "    - results_df: DataFrame с результатами экспериментов\n",
        "    - test_data_available: bool, указывает, есть ли тестовые данные\n",
        "    \"\"\"\n",
        "    n_neurons_list = sorted(results_df['n_neurons'].unique())\n",
        "    n_control_points_list = sorted(results_df['n_control_points'].unique())\n",
        "\n",
        "    # Создаем фигуру\n",
        "    fig, ax = plt.subplots(1, 2 if test_data_available else 1, figsize=(16, 8 if test_data_available else 6))\n",
        "    ax = [ax] if not test_data_available else ax\n",
        "\n",
        "    # График зависимости ошибки от числа нейронов\n",
        "    for n_points in n_control_points_list:\n",
        "        subset = results_df[results_df['n_control_points'] == n_points]\n",
        "        ax[0].plot(subset['n_neurons'], subset['train_mse'], 'o-', label=f'Control Points={n_points}')\n",
        "\n",
        "    ax[0].set_xlabel('Число нейронов')\n",
        "    ax[0].set_ylabel('MSE на обучающей выборке')\n",
        "    ax[0].set_title('Зависимость ошибки от числа нейронов')\n",
        "    ax[0].legend()\n",
        "    ax[0].grid(True)\n",
        "\n",
        "    if test_data_available:\n",
        "        # График сравнения ошибок\n",
        "        for n_points in n_control_points_list:\n",
        "            subset = results_df[results_df['n_control_points'] == n_points]\n",
        "            ax[1].plot(subset['n_neurons'], subset['train_mse'], 'o-', label=f'Train, CP={n_points}')\n",
        "            ax[1].plot(subset['n_neurons'], subset['test_mse'], 'x--', label=f'Test, CP={n_points}')\n",
        "\n",
        "        ax[1].set_xlabel('Число нейронов')\n",
        "        ax[1].set_ylabel('MSE')\n",
        "        ax[1].set_title('Сравнение обучающей и тестовой ошибок')\n",
        "        ax[1].legend()\n",
        "        ax[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def generate_demo_data(n_samples=100, noise=0.1, func_type='sin'):\n",
        "    \"\"\"\n",
        "    Генерирует демонстрационные данные для KAN-сети\n",
        "\n",
        "    Parameters:\n",
        "    - n_samples: Количество точек\n",
        "    - noise: Уровень шума\n",
        "    - func_type: Тип функции ('sin', 'exp', 'quadratic', '2d', 'classification', 'complex')\n",
        "\n",
        "    Returns:\n",
        "    - X: Входные данные\n",
        "    - y: Целевые значения\n",
        "    \"\"\"\n",
        "    if func_type == 'sin':\n",
        "        X = np.linspace(-5, 5, n_samples).reshape(-1, 1)\n",
        "        y = np.sin(X.flatten()) + noise * np.random.randn(n_samples)\n",
        "    elif func_type == 'exp':\n",
        "        X = np.linspace(-2, 2, n_samples).reshape(-1, 1)\n",
        "        y = np.exp(-X.flatten()**2) + noise * np.random.randn(n_samples)\n",
        "    elif func_type == 'quadratic':\n",
        "        X = np.linspace(-3, 3, n_samples).reshape(-1, 1)\n",
        "        y = 0.5 * X.flatten()**2 - 1.5 * X.flatten() + 2 + noise * np.random.randn(n_samples)\n",
        "    elif func_type == '2d':\n",
        "        X, y = make_friedman2(n_samples=n_samples, noise=noise, random_state=42)\n",
        "        X = X[:, :2]  # Ограничиваем до 2 признаков\n",
        "    elif func_type == 'classification':\n",
        "        X, y = make_circles(n_samples=n_samples, noise=noise, factor=0.5, random_state=42)\n",
        "    else:  # complex\n",
        "        X = np.linspace(-5, 5, n_samples).reshape(-1, 1)\n",
        "        y = np.sin(X.flatten()) * np.exp(-0.1 * X.flatten()**2) + noise * np.random.randn(n_samples)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def generate_advanced_demo_data(n_samples=200, noise=0.1, func_type='multimodal'):\n",
        "    \"\"\"\n",
        "    Генерирует сложные демонстрационные данные для KAN-сети\n",
        "\n",
        "    Parameters:\n",
        "    - n_samples: Количество точек\n",
        "    - noise: Уровень шума\n",
        "    - func_type: Тип функции ('multimodal', 'discontinuous', 'multidimensional', 'noisy_peaks', 'complex_3d')\n",
        "\n",
        "    Returns:\n",
        "    - X: Входные данные\n",
        "    - y: Целевые значения\n",
        "    \"\"\"\n",
        "    if func_type == 'multimodal':\n",
        "        X = np.linspace(-8, 8, n_samples).reshape(-1, 1)\n",
        "        y = np.sin(X.flatten()) + 0.5 * np.sin(3 * X.flatten()) + noise * np.random.randn(n_samples)\n",
        "    elif func_type == 'discontinuous':\n",
        "        X = np.linspace(-5, 5, n_samples).reshape(-1, 1)\n",
        "        y = np.zeros(n_samples)\n",
        "        mask1 = X.flatten() < -2\n",
        "        mask2 = (X.flatten() >= -2) & (X.flatten() < 1)\n",
        "        mask3 = X.flatten() >= 1\n",
        "        y[mask1] = -1 + noise * np.random.randn(np.sum(mask1))\n",
        "        y[mask2] = np.sin(X.flatten()[mask2] * 2) + noise * np.random.randn(np.sum(mask2))\n",
        "        y[mask3] = 1 + 0.5 * np.sin(X.flatten()[mask3]) + noise * np.random.randn(np.sum(mask3))\n",
        "    elif func_type == 'multidimensional':\n",
        "        X, y = make_friedman3(n_samples=n_samples, noise=noise, random_state=42)\n",
        "        X = X[:, :3]  # Ограничиваем до 3 признаков\n",
        "    elif func_type == 'noisy_peaks':\n",
        "        X = np.linspace(-5, 5, n_samples).reshape(-1, 1)\n",
        "        base = np.sin(X.flatten()) * np.exp(-0.1 * X.flatten()**2)\n",
        "        peaks = np.zeros(n_samples)\n",
        "        for _ in range(10):\n",
        "            pos = np.random.randint(0, n_samples)\n",
        "            width = np.random.randint(5, 20)\n",
        "            height = np.random.uniform(1, 3)\n",
        "            start = max(0, pos - width // 2)\n",
        "            end = min(n_samples, pos + width // 2)\n",
        "            peaks[start:end] = height * np.exp(-0.5 * ((np.arange(start, end) - pos) / (width / 5))**2)\n",
        "        y = base + peaks + noise * np.random.randn(n_samples)\n",
        "    elif func_type == 'complex_3d':\n",
        "        x = np.linspace(-3, 3, int(np.sqrt(n_samples)))\n",
        "        y = np.linspace(-3, 3, int(np.sqrt(n_samples)))\n",
        "        xx, yy = np.meshgrid(x, y)\n",
        "        X = np.column_stack([xx.ravel(), yy.ravel()])\n",
        "        z = np.sin(np.sqrt(xx**2 + yy**2)) + 0.1 * xx * yy + np.exp(-0.1 * (xx**2 + yy**2)) * np.cos(xx * yy)\n",
        "        y = z.ravel() + noise * np.random.randn(X.shape[0])\n",
        "    else:\n",
        "        X = np.linspace(-5, 5, n_samples).reshape(-1, 1)\n",
        "        y = 0.5 * X.flatten()**2 + np.sin(X.flatten() * 3) + noise * np.random.randn(n_samples)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def visualize_metrics(metrics_dict, title=\"Метрики качества аппроксимации KAN\"):\n",
        "    \"\"\"\n",
        "    Визуализирует метрики качества в виде графика\n",
        "\n",
        "    Parameters:\n",
        "    - metrics_dict: Словарь с метриками\n",
        "    - title: Заголовок графика\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    metrics = list(metrics_dict.keys())\n",
        "    values = list(metrics_dict.values())\n",
        "    bars = ax.bar(metrics, values, color='skyblue')\n",
        "\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        if height < 1e-10:\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., 0.01, f'{height:.2e}',\n",
        "                    ha='center', va='bottom', rotation=45)\n",
        "        else:\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.02 * max(values),\n",
        "                    f'{height:.4f}', ha='center', va='bottom')\n",
        "\n",
        "    ax.set_title(title)\n",
        "    ax.set_ylabel('Значение')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5AtpX5iwgN93"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_kan_formation():\n",
        "    \"\"\"\n",
        "    Демонстрация формирования B-сплайн функций в KAN-сети\n",
        "    с подробными объяснениями для образовательных целей\n",
        "    \"\"\"\n",
        "    print(\"ДЕМОНСТРАЦИЯ: Формирование B-сплайн функций в KAN\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Эта демонстрация покажет, как KAN-сеть создает и использует\")\n",
        "    print(\"B-сплайн функции для аппроксимации данных.\\n\")\n",
        "\n",
        "    # === 1D ДЕМОНСТРАЦИЯ ===\n",
        "    print(\"ЧАСТЬ 1: ОДНОМЕРНЫЙ СЛУЧАЙ (1D)\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    X, y = generate_demo_data(n_samples=100, noise=0.1, func_type='sin')\n",
        "\n",
        "    print(f\"✓ Создано {len(X)} точек данных\")\n",
        "    print(f\"✓ Диапазон X: от {X.min():.2f} до {X.max():.2f}\")\n",
        "    print(f\"✓ Диапазон Y: от {y.min():.2f} до {y.max():.2f}\")\n",
        "\n",
        "    print(\"\\nСоздаем KAN-сеть\")\n",
        "    model = KANNetwork(n_neurons=5, num_control_points=20, degree=2, input_dim=1)\n",
        "    print(f\"✓ Конфигурация: {model.n_neurons} нейронов, {model.num_control_points} контрольных точек\")\n",
        "\n",
        "    print(\"\\nОбучаем модель\")\n",
        "    model.fit(X, y, epochs=500, animate=True)\n",
        "\n",
        "    print(\"\\nВизуализируем B-сплайн функции с обучающими данными\")\n",
        "    model.visualize_spline_functions(X, feature_names=['X'], X_train=X, y_train=y)\n",
        "\n",
        "    # === 2D ДЕМОНСТРАЦИЯ ===\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\" ЧАСТЬ 2: ДВУМЕРНЫЙ СЛУЧАЙ (2D)\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    print(\"Генерируем 2D данные для регрессии\")\n",
        "    X_2d, y_2d = generate_demo_data(n_samples=200, noise=0.1, func_type='2d')\n",
        "\n",
        "    print(f\"✓ Создано {len(X_2d)} точек данных\")\n",
        "    print(f\"✓ Диапазон X1: от {X_2d[:, 0].min():.2f} до {X_2d[:, 0].max():.2f}\")\n",
        "    print(f\"✓ Диапазон X2: от {X_2d[:, 1].min():.2f} до {X_2d[:, 1].max():.2f}\")\n",
        "    print(f\"✓ Диапазон Y: от {y_2d.min():.2f} до {y_2d.max():.2f}\")\n",
        "\n",
        "    print(\"\\nСоздаем 2D KAN-сеть\")\n",
        "    model_2d = KANNetwork(n_neurons=9, num_control_points=20, degree=2, input_dim=2)\n",
        "    print(f\"✓ Конфигурация: {model_2d.n_neurons} нейронов, {model_2d.num_control_points} контрольных точек\")\n",
        "\n",
        "    print(\"\\nОбучаем модель\")\n",
        "    model_2d.fit(X_2d, y_2d, epochs=500, animate=True)\n",
        "\n",
        "    print(\"\\nВизуализируем B-сплайн функции в 2D с обучающими данными\")\n",
        "    model_2d.visualize_spline_functions(X_2d, feature_names=['X1', 'X2'], X_train=X_2d, y_train=y_2d)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\" ОБРАЗОВАТЕЛЬНЫЕ ВЫВОДЫ\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\" ЧТО МЫ УЗНАЛИ:\")\n",
        "    print(\"   1. B-сплайны создают локальные области влияния с четкими интервалами\")\n",
        "    print(\"   2. Каждая функция активна в пределах своих узлов\")\n",
        "    print(\"   3. Итоговый результат = композиция сплайнов через нейроны\")\n",
        "    print(\"   4. В 2D случае сплайны формируют адаптивные поверхности\")\n",
        "    print(\"   5. KAN автоматически оптимизирует контрольные точки при обучении\")\n",
        "\n",
        "    print(\"\\n ПРИНЦИП РАБОТЫ:\")\n",
        "    print(\"   • Новая точка активирует сплайны в соответствующих интервалах\")\n",
        "    print(\"   • Активации комбинируются через обучаемые веса\")\n",
        "    print(\"   • Это обеспечивает интерпретируемую аппроксимацию сложных функций\")\n",
        "\n",
        "    print(f\"\\n Демонстрация завершена!\")\n",
        "    print(f\"   Изучено {model.n_neurons} нейронов в 1D и {model_2d.n_neurons} в 2D\")"
      ],
      "metadata": {
        "id": "l7DiCun2r6ez"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_experiment_neurons_points():\n",
        "    \"\"\"\n",
        "    Демонстрация экспериментов с разным числом нейронов и контрольных точек\n",
        "    \"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"ЭКСПЕРИМЕНТЫ С ЧИСЛОМ НЕЙРОНОВ И КОНТРОЛЬНЫМИ ТОЧКАМИ\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    print(\"\\n ЧТО МЫ ИЗУЧАЕМ:\")\n",
        "    print(\"   • Как число нейронов влияет на аппроксимацию\")\n",
        "    print(\"   • Как число контрольных точек влияет на гибкость сплайнов\")\n",
        "    print(\"   • Поиск баланса между точностью и обобщением\")\n",
        "\n",
        "    print(\"\\n УСЛОВИЯ ЭКСПЕРИМЕНТА:\")\n",
        "    print(\"   • Функция: сложная нелинейная функция с шумом\")\n",
        "    print(\"   • Размер выборки: 200 точек (140 для обучения, 60 для тестирования)\")\n",
        "    print(\"   • Уровень шума: 20% для реальных условий\")\n",
        "\n",
        "    print(\"\\n ПАРАМЕТРЫ ДЛЯ ИССЛЕДОВАНИЯ:\")\n",
        "    print(\"   • Число нейронов: 3, 5, 7, 10, 15\")\n",
        "    print(\"     - Меньше нейронов: простые модели, риск недообучения\")\n",
        "    print(\"     - Больше нейронов: сложные модели, риск переобучения\")\n",
        "    print(\"   • Контрольные точки: 5, 10, 15, 20\")\n",
        "    print(\"     - Меньше точек: более гладкие сплайны\")\n",
        "    print(\"     - Больше точек: более детализированные сплайны\")\n",
        "\n",
        "\n",
        "    X, y = generate_demo_data(n_samples=200, noise=0.2, func_type='complex')\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    print(f\"✓ Данные разделены: {len(X_train)} для обучения, {len(X_test)} для тестирования\")\n",
        "\n",
        "    n_neurons_list = [3, 5, 7, 10, 15]\n",
        "    n_control_points_list = [5, 10, 15, 20]\n",
        "    print(f\"✓ Будет протестировано {len(n_neurons_list) * len(n_control_points_list)} комбинаций параметров\")\n",
        "\n",
        "    print(\"\\nПроведение экспериментов\")\n",
        "    results = experiment_with_kan(X_train, y_train, n_neurons_list, n_control_points_list, X_test, y_test)\n",
        "\n",
        "    print(\"\\n РЕЗУЛЬТАТЫ ЭКСПЕРИМЕНТОВ\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    visualize_experiment_results(results, test_data_available=True)\n",
        "\n",
        "    print(\"\\n СВОДКА РЕЗУЛЬТАТОВ:\")\n",
        "    print(f\"   • Всего протестировано комбинаций: {len(results)}\")\n",
        "    print(f\"   • Минимальная ошибка на тесте: {results['test_mse'].min():.6f}\")\n",
        "    print(f\"   • Максимальная ошибка на тесте: {results['test_mse'].max():.6f}\")\n",
        "    print(f\"   • Средняя ошибка на тесте: {results['test_mse'].mean():.6f}\")\n",
        "\n",
        "    best_idx = results['test_mse'].idxmin()\n",
        "    best_params = results.iloc[best_idx]\n",
        "\n",
        "    print(f\"\\n ЛУЧШИЕ ПАРАМЕТРЫ:\")\n",
        "    print(f\"   • Число нейронов: {int(best_params['n_neurons'])}\")\n",
        "    print(f\"   • Контрольные точки: {int(best_params['n_control_points'])}\")\n",
        "    print(f\"   • Ошибка на обучающей выборке: {best_params['train_mse']:.6f}\")\n",
        "    print(f\"   • Ошибка на тестовой выборке: {best_params['test_mse']:.6f}\")\n",
        "\n",
        "    overfit_ratio = best_params['test_mse'] / best_params['train_mse']\n",
        "    if overfit_ratio > 2.0:\n",
        "        print(\"Модель может переобучаться\")\n",
        "    elif overfit_ratio < 1.2:\n",
        "        print(\"Модель хорошо обобщает\")\n",
        "    else:\n",
        "        print(\"Умеренное переобучение\")\n",
        "\n",
        "    print(f\"\\n ВИЗУАЛИЗАЦИЯ ЛУЧШЕЙ МОДЕЛИ\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    best_model = KANNetwork(n_neurons=int(best_params['n_neurons']), num_control_points=int(best_params['n_control_points']))\n",
        "    best_model.fit(X_train, y_train)\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.scatter(X_train, y_train, alpha=0.6, color='blue', s=30, label='Обучающие данные')\n",
        "    plt.scatter(X_test, y_test, alpha=0.6, color='green', s=30, label='Тестовые данные')\n",
        "    sort_idx = np.argsort(X_test.flatten())\n",
        "    plt.plot(X_test[sort_idx], y_pred[sort_idx], 'r-', linewidth=2, label='Предсказание KAN')\n",
        "    plt.title(f'Лучшая модель: {int(best_params[\"n_neurons\"])} нейронов, {int(best_params[\"n_control_points\"])} точек')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('Y')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    x_range = np.linspace(X.min(), X.max(), 300)\n",
        "    spline_outputs = best_model.get_spline_outputs(x_range.reshape(-1, 1))\n",
        "    for i, output in enumerate(spline_outputs):\n",
        "        plt.plot(x_range, output, alpha=0.7, label=f'Сплайн {i+1}')\n",
        "    plt.title('B-сплайн функции (активации нейронов)')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('Активация сплайна')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n ВЫВОДЫ И РЕКОМЕНДАЦИИ:\")\n",
        "    print(\"-\" * 40)\n",
        "    best_n_neurons = int(best_params['n_neurons'])\n",
        "    best_n_points = int(best_params['n_control_points'])\n",
        "\n",
        "    if best_n_neurons <= 5:\n",
        "        print(\"   • Малое число нейронов оптимально\")\n",
        "        print(\"     - Простая модель с хорошим обобщением\")\n",
        "    else:\n",
        "        print(\"   • Большее число нейронов лучше\")\n",
        "        print(\"     - Сложная функция требует больше нейронов\")\n",
        "\n",
        "    if best_n_points <= 10:\n",
        "        print(\"   • Меньше контрольных точек лучше\")\n",
        "        print(\"     - Гладкие сплайны подходят для данных\")\n",
        "    else:\n",
        "        print(\"   • Больше контрольных точек лучше\")\n",
        "        print(\"     - Детализированные сплайны для сложных данных\")\n",
        "\n",
        "    print(f\"\\n Полная таблица результатов:\")\n",
        "    print(results.round(6))\n",
        "    print(\"\\n Эксперимент завершен!\")\n",
        "\n",
        "def demo_dataset_comparison():\n",
        "    \"\"\"\n",
        "    Демонстрация сравнения результатов KAN на разных наборах данных\n",
        "    \"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"СРАВНЕНИЕ РЕЗУЛЬТАТОВ KAN НА РАЗНЫХ НАБОРАХ ДАННЫХ\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    print(\"\\nЦЕЛЬ ЭКСПЕРИМЕНТА:\")\n",
        "    print(\"Оценить универсальность KAN на разных типах функций.\")\n",
        "\n",
        "    print(\"\\nУСЛОВИЯ ЭКСПЕРИМЕНТА:\")\n",
        "    print(\"• Количество образцов: 200\")\n",
        "    print(\"• Уровень шума: 0.1\")\n",
        "    print(\"• Разделение: 70% обучение / 30% тестирование\")\n",
        "    print(\"• Число нейронов: 7\")\n",
        "    print(\"• Контрольные точки: 10\")\n",
        "\n",
        "    print(\"\\nТИПЫ ДАННЫХ:\")\n",
        "    print(\"1. SIN - Периодическая функция\")\n",
        "    print(\"2. EXP - Гауссова функция\")\n",
        "    print(\"3. COMPLEX - Комбинированная функция\")\n",
        "\n",
        "    print(\"\\nЗапуск эксперимента...\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    datasets = {\n",
        "        'sin': generate_demo_data(n_samples=200, noise=0.1, func_type='sin'),\n",
        "        'exp': generate_demo_data(n_samples=200, noise=0.1, func_type='exp'),\n",
        "        'complex': generate_demo_data(n_samples=200, noise=0.1, func_type='complex')\n",
        "    }\n",
        "\n",
        "    n_neurons = 7\n",
        "    n_control_points = 10\n",
        "    fig, axes = plt.subplots(len(datasets), 1, figsize=(12, 4 * len(datasets)))\n",
        "    results_summary = {}\n",
        "\n",
        "    for i, (name, (X, y)) in enumerate(datasets.items()):\n",
        "        print(f\"\\nОБРАБОТКА НАБОРА ДАННЫХ: {name.upper()}\")\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "        model = KANNetwork(n_neurons=n_neurons, num_control_points=n_control_points)\n",
        "        print(f\"  Обучение KAN-сети с {n_neurons} нейронами...\")\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        train_mse = np.mean((y_train_pred.flatten() - y_train) ** 2)\n",
        "        test_mse = np.mean((y_test_pred.flatten() - y_test) ** 2)\n",
        "        train_r2 = 1 - (np.sum((y_train - y_train_pred.flatten()) ** 2) / np.sum((y_train - np.mean(y_train)) ** 2))\n",
        "        test_r2 = 1 - (np.sum((y_test - y_test_pred.flatten()) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2))\n",
        "\n",
        "        results_summary[name] = {\n",
        "            'train_mse': train_mse,\n",
        "            'test_mse': test_mse,\n",
        "            'train_r2': train_r2,\n",
        "            'test_r2': test_r2,\n",
        "            'overfitting': abs(test_mse - train_mse)\n",
        "        }\n",
        "\n",
        "        print(f\"  ✓ Train MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}\")\n",
        "        print(f\"  ✓ Train R²: {train_r2:.4f}, Test R²: {test_r2:.4f}\")\n",
        "\n",
        "        train_sort_idx = np.argsort(X_train.flatten())\n",
        "        test_sort_idx = np.argsort(X_test.flatten())\n",
        "        ax = axes[i]\n",
        "        ax.scatter(X_train, y_train, alpha=0.6, s=30, label='Обучающие данные', color='blue')\n",
        "        ax.scatter(X_test, y_test, alpha=0.6, s=30, label='Тестовые данные', color='magenta')\n",
        "        ax.plot(X_train[train_sort_idx], y_train_pred[train_sort_idx], 'r-', linewidth=2.5, label='Предсказания (обуч.)')\n",
        "        ax.plot(X_test[test_sort_idx], y_test_pred[test_sort_idx], 'g--', linewidth=2.5, label='Предсказания (тест)')\n",
        "        ax.set_title(f'Набор \"{name}\" | Train MSE: {train_mse:.4f} | Test MSE: {test_mse:.4f} | R²: {test_r2:.3f}')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_xlabel('X')\n",
        "        ax.set_ylabel('Y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"АНАЛИЗ РЕЗУЛЬТАТОВ\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    best_dataset = min(results_summary.keys(), key=lambda k: results_summary[k]['test_mse'])\n",
        "    worst_dataset = max(results_summary.keys(), key=lambda k: results_summary[k]['test_mse'])\n",
        "    most_overfitted = max(results_summary.keys(), key=lambda k: results_summary[k]['overfitting'])\n",
        "\n",
        "    print(f\"\\n СВОДКА:\")\n",
        "    for name, results in results_summary.items():\n",
        "        status = \"  ЛУЧШИЙ РЕЗУЛЬТАТ\" if name == best_dataset else \"  СЛОЖНЕЙШАЯ ЗАДАЧА\" if name == worst_dataset else \"\"\n",
        "        print(f\"\\n{name.upper()}{status}:\")\n",
        "        print(f\"  • Ошибка на тесте: {results['test_mse']:.4f}\")\n",
        "        print(f\"  • R²: {results['test_r2']:.3f} ({'отлично' if results['test_r2'] > 0.9 else 'хорошо' if results['test_r2'] > 0.7 else 'удовлетворительно'})\")\n",
        "        print(f\"  • Переобучение: {results['overfitting']:.4f} ({'низкое' if results['overfitting'] < 0.01 else 'умеренное' if results['overfitting'] < 0.05 else 'высокое'})\")\n",
        "\n",
        "    print(f\"\\n ВЫВОДЫ:\")\n",
        "    print(f\"• Лучший результат: '{best_dataset}'\")\n",
        "    print(f\"• Сложнейшая задача: '{worst_dataset}'\")\n",
        "    print(f\"• Наибольшее переобучение: '{most_overfitted}'\")\n",
        "    print(\"\\n Эксперимент завершен!\")\n",
        "\n",
        "def plot_dataset_results(X_train, y_train, X_test, y_test, y_train_pred, y_test_pred, title=\"Результаты аппроксимации\"):\n",
        "    \"\"\"\n",
        "    Визуализирует результаты аппроксимации KAN\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    if X_train.shape[1] == 1:\n",
        "        train_sort_idx = np.argsort(X_train.flatten())\n",
        "        test_sort_idx = np.argsort(X_test.flatten())\n",
        "        plt.scatter(X_train, y_train, alpha=0.5, label='Обучающие данные')\n",
        "        plt.scatter(X_test, y_test, alpha=0.5, label='Тестовые данные')\n",
        "        plt.plot(X_train[train_sort_idx], y_train_pred[train_sort_idx], 'r-', linewidth=2, label='Предсказания (обуч.)')\n",
        "        plt.plot(X_test[test_sort_idx], y_test_pred[test_sort_idx], 'g--', linewidth=2, label='Предсказания (тест)')\n",
        "    elif X_train.shape[1] == 2:\n",
        "        from mpl_toolkits.mplot3d import Axes3D\n",
        "        fig = plt.figure(figsize=(15, 10))\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        ax.scatter(X_train[:, 0], X_train[:, 1], y_train, color='blue', alpha=0.5, label='Обучающие данные')\n",
        "        ax.scatter(X_test[:, 0], X_test[:, 1], y_test, color='green', alpha=0.5, label='Тестовые данные')\n",
        "        ax.scatter(X_test[:, 0], X_test[:, 1], y_test_pred, color='red', alpha=0.5, label='Предсказания')\n",
        "        ax.set_xlabel('X1')\n",
        "        ax.set_ylabel('X2')\n",
        "        ax.set_zlabel('y')\n",
        "        plt.title(title)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        return\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def demo_advanced_experiments():\n",
        "    \"\"\"\n",
        "    Демонстрация расширенных экспериментов с KAN-сетями\n",
        "    \"\"\"\n",
        "    print(\"=== РАСШИРЕННЫЕ ЭКСПЕРИМЕНТЫ С KAN-СЕТЯМИ ===\")\n",
        "    print(\"\\nЦЕЛЬ ЭКСПЕРИМЕНТА:\")\n",
        "    print(\"Исследование возможностей KAN на сложных функциях.\")\n",
        "\n",
        "    print(\"\\nТИПЫ ФУНКЦИЙ:\")\n",
        "    print(\"• Многомодальная: несколько пиков и впадин\")\n",
        "    print(\"• Разрывная: скачки и разрывы\")\n",
        "    print(\"• С шумными всплесками: случайные аномалии\")\n",
        "\n",
        "    print(\"\\nПАРАМЕТРЫ ЭКСПЕРИМЕНТА:\")\n",
        "    print(\"• Число нейронов: 5, 10, 15\")\n",
        "    print(\"• Контрольные точки: 5, 10, 15\")\n",
        "    print(\"• Размер выборки: 300 точек (70% обучение, 30% тест)\")\n",
        "\n",
        "    advanced_datasets = {\n",
        "        'Многомодальная': generate_advanced_demo_data(n_samples=300, noise=0.1, func_type='multimodal'),\n",
        "        'Разрывная': generate_advanced_demo_data(n_samples=300, noise=0.1, func_type='discontinuous'),\n",
        "        'С шумными всплесками': generate_advanced_demo_data(n_samples=300, noise=0.1, func_type='noisy_peaks')\n",
        "    }\n",
        "\n",
        "    n_neurons_list = [5, 10, 15]\n",
        "    n_control_points_list = [5, 10, 15]\n",
        "\n",
        "    print(f\"Сгенерированы {len(advanced_datasets)} типа функций\")\n",
        "    print(f\"Протестировано {len(n_neurons_list) * len(n_control_points_list)} комбинаций\")\n",
        "\n",
        "    all_results = {}\n",
        "    best_params = {}\n",
        "    best_metrics = {}\n",
        "\n",
        "    for idx, (dataset_name, (X, y)) in enumerate(advanced_datasets.items(), 1):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ЭКСПЕРИМЕНТ {idx}/3: {dataset_name.upper()} ФУНКЦИЯ\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        if dataset_name == 'Многомодальная':\n",
        "            print(\"   ОПИСАНИЕ: Несколько пиков и впадин.\")\n",
        "            print(\"   Ожидание: Требуется больше нейронов.\")\n",
        "        elif dataset_name == 'Разрывная':\n",
        "            print(\"   ОПИСАНИЕ: Резкие скачки.\")\n",
        "            print(\"   Ожидание: Меньше точек для локализации.\")\n",
        "        elif dataset_name == 'С шумными всплесками':\n",
        "            print(\"   ОПИСАНИЕ: Случайные пики.\")\n",
        "            print(\"   Ожидание: Средние параметры.\")\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "        print(f\"\\n Размеры выборок: {len(X_train)} обучение, {len(X_test)} тест\")\n",
        "\n",
        "        print(f\"\\n ПОИСК ОПТИМАЛЬНЫХ ПАРАМЕТРОВ\")\n",
        "        results = experiment_with_kan(X_train, y_train, n_neurons_list, n_control_points_list, X_test, y_test)\n",
        "        all_results[dataset_name] = results\n",
        "\n",
        "        best_idx = results['test_mse'].idxmin()\n",
        "        best_params[dataset_name] = results.iloc[best_idx]\n",
        "\n",
        "        print(f\"\\n РЕЗУЛЬТАТЫ:\")\n",
        "        print(f\"   • Нейроны: {int(best_params[dataset_name]['n_neurons'])}\")\n",
        "        print(f\"   • Точки: {int(best_params[dataset_name]['n_control_points'])}\")\n",
        "        print(f\"   • MSE: {best_params[dataset_name]['test_mse']:.6f}\")\n",
        "\n",
        "        best_model = KANNetwork(\n",
        "            n_neurons=int(best_params[dataset_name]['n_neurons']),\n",
        "            num_control_points=int(best_params[dataset_name]['n_control_points'])\n",
        "        )\n",
        "        best_model.fit(X_train, y_train)\n",
        "        y_train_pred = best_model.predict(X_train)\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "        train_metrics = best_model.calculate_metrics(y_train, y_train_pred)\n",
        "        test_metrics = best_model.calculate_metrics(y_test, y_test_pred)\n",
        "        best_metrics[dataset_name] = {'train': train_metrics, 'test': test_metrics}\n",
        "\n",
        "        print(f\"\\n МЕТРИКИ:\")\n",
        "        for metric, value in test_metrics.items():\n",
        "            print(f\"   • {metric.upper()}: {value:.6f}\")\n",
        "\n",
        "        r2_score = test_metrics.get('r2', 0)\n",
        "        print(f\"\\n КАЧЕСТВО: {'Отличное' if r2_score > 0.9 else 'Хорошее' if r2_score > 0.8 else 'Удовлетворительное'} (R² = {r2_score:.3f})\")\n",
        "\n",
        "        visualize_metrics(test_metrics, title=f\"Метрики для {dataset_name}\")\n",
        "        plot_dataset_results(X_train, y_train, X_test, y_test, y_train_pred, y_test_pred,\n",
        "                            title=f\"Аппроксимация: {dataset_name}\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\" ОБЩИЙ АНАЛИЗ\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    print(\"\\n ЛУЧШИЕ ПАРАМЕТРЫ:\")\n",
        "    for dataset_name, params in best_params.items():\n",
        "        print(f\"   {dataset_name:20} | Нейроны: {int(params['n_neurons']):2d} | Точки: {int(params['n_control_points']):2d} | MSE: {params['test_mse']:.6f}\")\n",
        "\n",
        "    print(\"\\n ВЫВОДЫ:\")\n",
        "    print(\"   • KAN эффективно аппроксимирует сложные функции\")\n",
        "    print(\"   • Баланс нейронов и точек важен для обобщения\")\n",
        "    print(\"\\n Эксперименты завершены!\")\n",
        "\n",
        "    return all_results, best_params, best_metrics"
      ],
      "metadata": {
        "id": "e0urDFU4tEsZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_dataset_comparison():\n",
        "    \"\"\"\n",
        "    Демонстрация сравнения результатов KAN на разных наборах данных\n",
        "    \"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"СРАВНЕНИЕ РЕЗУЛЬТАТОВ KAN НА РАЗНЫХ НАБОРАХ ДАННЫХ\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    print(\"\\nЦЕЛЬ ЭКСПЕРИМЕНТА:\")\n",
        "    print(\"Оценить универсальность KAN на разных типах функций.\")\n",
        "\n",
        "    print(\"\\nУСЛОВИЯ ЭКСПЕРИМЕНТА:\")\n",
        "    print(\"• Количество образцов: 200\")\n",
        "    print(\"• Уровень шума: 0.1\")\n",
        "    print(\"• Разделение: 70% обучение / 30% тестирование\")\n",
        "    print(\"• Число нейронов: 7\")\n",
        "    print(\"• Контрольные точки: 10\")\n",
        "\n",
        "    print(\"\\nТИПЫ ДАННЫХ:\")\n",
        "    print(\"1. SIN - Периодическая функция\")\n",
        "    print(\"2. EXP - Гауссова функция\")\n",
        "    print(\"3. COMPLEX - Комбинированная функция\")\n",
        "\n",
        "    datasets = {\n",
        "        'sin': generate_demo_data(n_samples=200, noise=0.1, func_type='sin'),\n",
        "        'exp': generate_demo_data(n_samples=200, noise=0.1, func_type='exp'),\n",
        "        'complex': generate_demo_data(n_samples=200, noise=0.1, func_type='complex')\n",
        "    }\n",
        "\n",
        "    n_neurons = 7\n",
        "    n_control_points = 10\n",
        "    fig, axes = plt.subplots(len(datasets), 1, figsize=(12, 4 * len(datasets)))\n",
        "    results_summary = {}\n",
        "\n",
        "    for i, (name, (X, y)) in enumerate(datasets.items()):\n",
        "        print(f\"\\nОБРАБОТКА НАБОРА ДАННЫХ: {name.upper()}\")\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "        model = KANNetwork(n_neurons=n_neurons, num_control_points=n_control_points)\n",
        "        print(f\"  Обучение KAN-сети с {n_neurons} нейронами\")\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        train_mse = np.mean((y_train_pred.flatten() - y_train) ** 2)\n",
        "        test_mse = np.mean((y_test_pred.flatten() - y_test) ** 2)\n",
        "        train_r2 = 1 - (np.sum((y_train - y_train_pred.flatten()) ** 2) / np.sum((y_train - np.mean(y_train)) ** 2))\n",
        "        test_r2 = 1 - (np.sum((y_test - y_test_pred.flatten()) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2))\n",
        "\n",
        "        results_summary[name] = {\n",
        "            'train_mse': train_mse,\n",
        "            'test_mse': test_mse,\n",
        "            'train_r2': train_r2,\n",
        "            'test_r2': test_r2,\n",
        "            'overfitting': abs(test_mse - train_mse)\n",
        "        }\n",
        "\n",
        "        print(f\"  ✓ Train MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}\")\n",
        "        print(f\"  ✓ Train R²: {train_r2:.4f}, Test R²: {test_r2:.4f}\")\n",
        "\n",
        "        train_sort_idx = np.argsort(X_train.flatten())\n",
        "        test_sort_idx = np.argsort(X_test.flatten())\n",
        "        ax = axes[i]\n",
        "        ax.scatter(X_train, y_train, alpha=0.6, s=30, label='Обучающие данные', color='blue')\n",
        "        ax.scatter(X_test, y_test, alpha=0.6, s=30, label='Тестовые данные', color='magenta')\n",
        "        ax.plot(X_train[train_sort_idx], y_train_pred[train_sort_idx], 'r-', linewidth=2.5, label='Предсказания (обуч.)')\n",
        "        ax.plot(X_test[test_sort_idx], y_test_pred[test_sort_idx], 'g--', linewidth=2.5, label='Предсказания (тест)')\n",
        "        ax.set_title(f'Набор \"{name}\" | Train MSE: {train_mse:.4f} | Test MSE: {test_mse:.4f} | R²: {test_r2:.3f}')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_xlabel('X')\n",
        "        ax.set_ylabel('Y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"АНАЛИЗ РЕЗУЛЬТАТОВ\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    best_dataset = min(results_summary.keys(), key=lambda k: results_summary[k]['test_mse'])\n",
        "    worst_dataset = max(results_summary.keys(), key=lambda k: results_summary[k]['test_mse'])\n",
        "    most_overfitted = max(results_summary.keys(), key=lambda k: results_summary[k]['overfitting'])\n",
        "\n",
        "    print(f\"\\n СВОДКА:\")\n",
        "    for name, results in results_summary.items():\n",
        "        status = \"  ЛУЧШИЙ РЕЗУЛЬТАТ\" if name == best_dataset else \"  СЛОЖНЕЙШАЯ ЗАДАЧА\" if name == worst_dataset else \"\"\n",
        "        print(f\"\\n{name.upper()}{status}:\")\n",
        "        print(f\"  • Ошибка на тесте: {results['test_mse']:.4f}\")\n",
        "        print(f\"  • R²: {results['test_r2']:.3f} ({'отлично' if results['test_r2'] > 0.9 else 'хорошо' if results['test_r2'] > 0.7 else 'удовлетворительно'})\")\n",
        "        print(f\"  • Переобучение: {results['overfitting']:.4f} ({'низкое' if results['overfitting'] < 0.01 else 'умеренное' if results['overfitting'] < 0.05 else 'высокое'})\")\n",
        "\n",
        "    print(f\"\\n ВЫВОДЫ:\")\n",
        "    print(f\"• Лучший результат: '{best_dataset}'\")\n",
        "    print(f\"• Сложнейшая задача: '{worst_dataset}'\")\n",
        "    print(f\"• Наибольшее переобучение: '{most_overfitted}'\")\n",
        "    print(\"\\n Эксперимент завершен!\")\n"
      ],
      "metadata": {
        "id": "znoal1BKtIqx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_dataset_results(X_train, y_train, X_test, y_test, y_train_pred, y_test_pred, title=\"Результаты аппроксимации\"):\n",
        "    \"\"\"\n",
        "    Визуализирует результаты аппроксимации KAN\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    if X_train.shape[1] == 1:\n",
        "        train_sort_idx = np.argsort(X_train.flatten())\n",
        "        test_sort_idx = np.argsort(X_test.flatten())\n",
        "        plt.scatter(X_train, y_train, alpha=0.5, label='Обучающие данные')\n",
        "        plt.scatter(X_test, y_test, alpha=0.5, label='Тестовые данные')\n",
        "        plt.plot(X_train[train_sort_idx], y_train_pred[train_sort_idx], 'r-', linewidth=2, label='Предсказания (обуч.)')\n",
        "        plt.plot(X_test[test_sort_idx], y_test_pred[test_sort_idx], 'g--', linewidth=2, label='Предсказания (тест)')\n",
        "    elif X_train.shape[1] == 2:\n",
        "        from mpl_toolkits.mplot3d import Axes3D\n",
        "        fig = plt.figure(figsize=(15, 10))\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        ax.scatter(X_train[:, 0], X_train[:, 1], y_train, color='blue', alpha=0.5, label='Обучающие данные')\n",
        "        ax.scatter(X_test[:, 0], X_test[:, 1], y_test, color='green', alpha=0.5, label='Тестовые данные')\n",
        "        ax.scatter(X_test[:, 0], X_test[:, 1], y_test_pred, color='red', alpha=0.5, label='Предсказания')\n",
        "        ax.set_xlabel('X1')\n",
        "        ax.set_ylabel('X2')\n",
        "        ax.set_zlabel('y')\n",
        "        plt.title(title)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        return\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "jbAdXc1ztNZz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_advanced_experiments():\n",
        "    \"\"\"\n",
        "    Демонстрация расширенных экспериментов с KAN-сетями\n",
        "    \"\"\"\n",
        "    print(\"=== РАСШИРЕННЫЕ ЭКСПЕРИМЕНТЫ С KAN-СЕТЯМИ ===\")\n",
        "    print(\"\\nЦЕЛЬ ЭКСПЕРИМЕНТА:\")\n",
        "    print(\"Исследование возможностей KAN на сложных функциях.\")\n",
        "\n",
        "    print(\"\\nТИПЫ ФУНКЦИЙ:\")\n",
        "    print(\"• Многомодальная: несколько пиков и впадин\")\n",
        "    print(\"• Разрывная: скачки и разрывы\")\n",
        "    print(\"• С шумными всплесками: случайные аномалии\")\n",
        "\n",
        "    print(\"\\nПАРАМЕТРЫ ЭКСПЕРИМЕНТА:\")\n",
        "    print(\"• Число нейронов: 5, 10, 15\")\n",
        "    print(\"• Контрольные точки: 5, 10, 15\")\n",
        "    print(\"• Размер выборки: 300 точек (70% обучение, 30% тест)\")\n",
        "\n",
        "    advanced_datasets = {\n",
        "        'Многомодальная': generate_advanced_demo_data(n_samples=300, noise=0.1, func_type='multimodal'),\n",
        "        'Разрывная': generate_advanced_demo_data(n_samples=300, noise=0.1, func_type='discontinuous'),\n",
        "        'С шумными всплесками': generate_advanced_demo_data(n_samples=300, noise=0.1, func_type='noisy_peaks')\n",
        "    }\n",
        "\n",
        "    n_neurons_list = [5, 10, 15]\n",
        "    n_control_points_list = [5, 10, 15]\n",
        "\n",
        "    print(f\"Сгенерированы {len(advanced_datasets)} типа функций\")\n",
        "    print(f\"Протестировано {len(n_neurons_list) * len(n_control_points_list)} комбинаций\")\n",
        "\n",
        "    all_results = {}\n",
        "    best_params = {}\n",
        "    best_metrics = {}\n",
        "\n",
        "    for idx, (dataset_name, (X, y)) in enumerate(advanced_datasets.items(), 1):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ЭКСПЕРИМЕНТ {idx}/3: {dataset_name.upper()} ФУНКЦИЯ\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        if dataset_name == 'Многомодальная':\n",
        "            print(\"   ОПИСАНИЕ: Несколько пиков и впадин.\")\n",
        "            print(\"   Ожидание: Требуется больше нейронов.\")\n",
        "        elif dataset_name == 'Разрывная':\n",
        "            print(\"   ОПИСАНИЕ: Резкие скачки.\")\n",
        "            print(\"   Ожидание: Меньше точек для локализации.\")\n",
        "        elif dataset_name == 'С шумными всплесками':\n",
        "            print(\"   ОПИСАНИЕ: Случайные пики.\")\n",
        "            print(\"   Ожидание: Средние параметры.\")\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "        print(f\"\\n Размеры выборок: {len(X_train)} обучение, {len(X_test)} тест\")\n",
        "\n",
        "        print(f\"\\n ПОИСК ОПТИМАЛЬНЫХ ПАРАМЕТРОВ\")\n",
        "        results = experiment_with_kan(X_train, y_train, n_neurons_list, n_control_points_list, X_test, y_test)\n",
        "        all_results[dataset_name] = results\n",
        "\n",
        "        best_idx = results['test_mse'].idxmin()\n",
        "        best_params[dataset_name] = results.iloc[best_idx]\n",
        "\n",
        "        print(f\"\\n РЕЗУЛЬТАТЫ:\")\n",
        "        print(f\"   • Нейроны: {int(best_params[dataset_name]['n_neurons'])}\")\n",
        "        print(f\"   • Точки: {int(best_params[dataset_name]['n_control_points'])}\")\n",
        "        print(f\"   • MSE: {best_params[dataset_name]['test_mse']:.6f}\")\n",
        "\n",
        "        best_model = KANNetwork(\n",
        "            n_neurons=int(best_params[dataset_name]['n_neurons']),\n",
        "            num_control_points=int(best_params[dataset_name]['n_control_points'])\n",
        "        )\n",
        "        best_model.fit(X_train, y_train)\n",
        "        y_train_pred = best_model.predict(X_train)\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "        train_metrics = best_model.calculate_metrics(y_train, y_train_pred)\n",
        "        test_metrics = best_model.calculate_metrics(y_test, y_test_pred)\n",
        "        best_metrics[dataset_name] = {'train': train_metrics, 'test': test_metrics}\n",
        "\n",
        "        print(f\"\\n МЕТРИКИ:\")\n",
        "        for metric, value in test_metrics.items():\n",
        "            print(f\"   • {metric.upper()}: {value:.6f}\")\n",
        "\n",
        "        r2_score = test_metrics.get('r2', 0)\n",
        "        print(f\"\\n КАЧЕСТВО: {'Отличное' if r2_score > 0.9 else 'Хорошее' if r2_score > 0.8 else 'Удовлетворительное'} (R² = {r2_score:.3f})\")\n",
        "\n",
        "        visualize_metrics(test_metrics, title=f\"Метрики для {dataset_name}\")\n",
        "        plot_dataset_results(X_train, y_train, X_test, y_test, y_train_pred, y_test_pred,\n",
        "                            title=f\"Аппроксимация: {dataset_name}\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\" ОБЩИЙ АНАЛИЗ\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    print(\"\\n ЛУЧШИЕ ПАРАМЕТРЫ:\")\n",
        "    for dataset_name, params in best_params.items():\n",
        "        print(f\"   {dataset_name:20} | Нейроны: {int(params['n_neurons']):2d} | Точки: {int(params['n_control_points']):2d} | MSE: {params['test_mse']:.6f}\")\n",
        "\n",
        "    print(\"\\n ВЫВОДЫ:\")\n",
        "    print(\"   • KAN эффективно аппроксимирует сложные функции\")\n",
        "    print(\"   • Баланс нейронов и точек важен для обобщения\")\n",
        "    print(\"\\n Эксперименты завершены!\")\n",
        "\n",
        "    return all_results, best_params, best_metrics"
      ],
      "metadata": {
        "id": "wULMXXzktLnc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_kan_training_process():\n",
        "    \"\"\"\n",
        "    Демонстрация процесса обучения KAN-сети\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ДЕМОНСТРАЦИЯ ОБУЧЕНИЯ СЕТИ КОЛМОГОРОВА-АРНОЛЬДА (KAN)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(\"\\nЦЕЛЬ ЭКСПЕРИМЕНТА:\")\n",
        "    print(\"Показать, как KAN-сеть обучается аппроксимировать синусоиду с шумом.\")\n",
        "\n",
        "    print(\"\\nВЫБРАННЫЕ ПАРАМЕТРЫ:\")\n",
        "    print(\"─\" * 50)\n",
        "\n",
        "    print(\" ДАННЫЕ:\")\n",
        "    print(\"  • Функция: синусоида — гладкая и периодическая\")\n",
        "    print(\"  • Точек: 100 — достаточно для наглядности\")\n",
        "    print(\"  • Шум: 0.2 — моделирует реальные данные\")\n",
        "    print(\"  • Обоснование: синусоида идеальна для демонстрации сходимости\")\n",
        "\n",
        "    print(\"\\n ПАРАМЕТРЫ KAN-СЕТИ:\")\n",
        "    print(\"  • Нейронов: 7 — баланс между точностью и простотой\")\n",
        "    print(\"  • Контрольных точек: 20 — для гибкости сплайнов\")\n",
        "    print(\"  • Эпох: 100 — достаточно для сходимости\")\n",
        "    print(\"  • Тип сплайнов: B-сплайны 2-й степени\")\n",
        "\n",
        "    print(\"\\n ЧТО ВЫ УВИДИТЕ:\")\n",
        "    print(\"  • Синие точки — данные с шумом\")\n",
        "    print(\"  • Красная линия — аппроксимация KAN\")\n",
        "    print(\"  • MSE — ошибка, уменьшающаяся с эпохами\")\n",
        "\n",
        "    print(\"\\n МЕХАНИЗМ ОБУЧЕНИЯ:\")\n",
        "    print(\"  1. Инициализация случайных контрольных точек\")\n",
        "    print(\"  2. Оптимизация весов и сплайнов через Adam\")\n",
        "    print(\"  3. Постепенное улучшение аппроксимации\")\n",
        "    print(\"  4. Уменьшение MSE с каждой эпохой\")\n",
        "\n",
        "    X, y = generate_demo_data(n_samples=100, noise=0.2, func_type='sin')\n",
        "    print(f\"\\nДанные: {len(X)} точек в диапазоне [{X.min():.2f}, {X.max():.2f}]\")\n",
        "\n",
        "    model = KANNetwork(n_neurons=7, num_control_points=20, degree=2, max_epochs=100, animation_interval=5)\n",
        "    print(\"Обучение с сохранением истории\")\n",
        "    model.fit(X, y, animate=True)\n",
        "\n",
        "    mse = model.training_history[-1].get('mse', 'N/A')\n",
        "    print(f\"Обучение завершено! Итоговая MSE: {mse:.6f}\")\n",
        "\n",
        "    ani = model.animate_training(X, y, interval=200)\n",
        "\n",
        "    try:\n",
        "        print(\"Сохранение анимации как 'kan_training.mp4'\")\n",
        "        ani.save('kan_training.mp4', writer='ffmpeg')\n",
        "        print(\"Анимация сохранена!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка сохранения: {e}\")\n",
        "        print(\"Анимация будет показана без сохранения.\")\n",
        "\n",
        "    print(\"\\nАНИМАЦИЯ ГОТОВА\")\n",
        "    print(\"  Наблюдайте, как сеть улучшает аппроксимацию синусоиды.\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nИТОГИ:\")\n",
        "    initial_mse = model.training_history[0].get('mse', 'N/A')\n",
        "    final_mse = model.training_history[-1].get('mse', 'N/A')\n",
        "    print(f\"  • Начальная MSE: {initial_mse:.6f}\")\n",
        "    print(f\"  • Финальная MSE: {final_mse:.6f}\")\n",
        "    print(f\"  • Эпох: {model.max_epochs}\")\n",
        "    improvement = ((initial_mse - final_mse) / initial_mse * 100) if initial_mse != 'N/A' and final_mse != 'N/A' else 0\n",
        "    print(f\"  • Улучшение: {improvement:.1f}%\")\n",
        "\n",
        "    print(\"\\nВЫВОДЫ:\")\n",
        "    print(\"  KAN успешно аппроксимирует зашумленные данные, демонстрируя\")\n",
        "    print(\"  эффективность B-сплайнов и интерпретируемость.\")\n",
        "    print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "cErxtBZetR7E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_kan_training_process_interactive():\n",
        "    \"\"\"\n",
        "    Интерактивная демонстрация обучения KAN-сети\n",
        "    \"\"\"\n",
        "    print(\"=== ИНТЕРАКТИВНОЕ ОБУЧЕНИЕ KAN-СЕТИ ===\")\n",
        "    print()\n",
        "\n",
        "    print(\"НАСТРОЙКА ПАРАМЕТРОВ:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            print(\"Число нейронов:\")\n",
        "            print(\"  Рекомендация: 3–15\")\n",
        "            print(\"  Меньше — проще модель, больше — точнее, но риск переобучения\")\n",
        "            n_neurons = int(input(\"Введите число нейронов (по умолчанию 7): \") or \"7\")\n",
        "            if n_neurons < 1:\n",
        "                print(\"Нейронов должно быть больше 0!\")\n",
        "                continue\n",
        "            elif n_neurons > 50:\n",
        "                print(\"Слишком много нейронов! Не более 50.\")\n",
        "                continue\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Введите целое число!\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            print(\"Контрольные точки сплайнов:\")\n",
        "            print(\"  Рекомендация: 5–20\")\n",
        "            print(\"  Меньше — гладкие сплайны, больше — детализированные\")\n",
        "            num_control_points = int(input(\"Введите число точек (по умолчанию 10): \") or \"10\")\n",
        "            if num_control_points < 3:\n",
        "                print(\"Точек должно быть не менее 3!\")\n",
        "                continue\n",
        "            elif num_control_points > 50:\n",
        "                print(\"Слишком много точек! Не более 50.\")\n",
        "                continue\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Введите целое число!\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            print(\"Число эпох обучения:\")\n",
        "            print(\"  Рекомендация: 50–200\")\n",
        "            print(\"  Меньше — быстрее, больше — точнее, но дольше\")\n",
        "            max_epochs = int(input(\"Введите число эпох (по умолчанию 100): \") or \"100\")\n",
        "            if max_epochs < 1:\n",
        "                print(\"Эпох должно быть больше 0!\")\n",
        "                continue\n",
        "            elif max_epochs > 1000:\n",
        "                print(\"Слишком много эпох! Не более 1000.\")\n",
        "                continue\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Введите целое число!\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            print(\"Интервал анимации (эпохи на кадр):\")\n",
        "            print(\"  Рекомендация: 1–10\")\n",
        "            print(\"  1 — каждый шаг, 5–10 — быстрее\")\n",
        "            animation_interval = int(input(\"Введите интервал (по умолчанию 5): \") or \"5\")\n",
        "            if animation_interval < 1:\n",
        "                print(\"Интервал должен быть больше 0!\")\n",
        "                continue\n",
        "            elif animation_interval > max_epochs:\n",
        "                print(f\"Интервал не может превышать эпох ({max_epochs})!\")\n",
        "                continue\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Введите целое число!\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    print(\"Выберите функцию для аппроксимации:\")\n",
        "    print(\"1. Синусоида (sin)\")\n",
        "    print(\"2. Экспонента (exp)\")\n",
        "    print(\"3. Квадратичная (quadratic)\")\n",
        "    print(\"4. Сложная (complex)\")\n",
        "    while True:\n",
        "        try:\n",
        "            func_choice = int(input(\"Выберите функцию (1–4, по умолчанию 1): \") or \"1\")\n",
        "            func_type = {1: 'sin', 2: 'exp', 3: 'quadratic', 4: 'complex'}.get(func_choice)\n",
        "            if func_type:\n",
        "                break\n",
        "            print(\"Выберите число от 1 до 4!\")\n",
        "        except ValueError:\n",
        "            print(\"Введите число!\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            print(\"Уровень шума:\")\n",
        "            print(\"  0.0 — без шума, 0.1 — слабый, 0.2 — умеренный, 0.3+ — сильный\")\n",
        "            noise = float(input(\"Введите шум (по умолчанию 0.2): \") or \"0.2\")\n",
        "            if noise < 0:\n",
        "                print(\"Шум не может быть отрицательным!\")\n",
        "                continue\n",
        "            elif noise > 1:\n",
        "                print(\"Слишком большой шум! Не более 1.0.\")\n",
        "                continue\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Введите число!\")\n",
        "\n",
        "    print()\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Параметры:\")\n",
        "    print(f\"  - Нейроны: {n_neurons}\")\n",
        "    print(f\"  - Контрольные точки: {num_control_points}\")\n",
        "    print(f\"  - Эпохи: {max_epochs}\")\n",
        "    print(f\"  - Интервал анимации: {animation_interval}\")\n",
        "    print(f\"  - Функция: {func_type}\")\n",
        "    print(f\"  - Шум: {noise}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    confirm = input(\"Запустить обучение? (y/n, по умолчанию y): \").lower() or \"y\"\n",
        "    if confirm not in ['y', 'yes', 'д', 'да']:\n",
        "        print(\"Демонстрация отменена.\")\n",
        "        return\n",
        "    X, y = generate_demo_data(n_samples=100, noise=noise, func_type=func_type)\n",
        "\n",
        "    model = KANNetwork(n_neurons=n_neurons, num_control_points=num_control_points,\n",
        "                       max_epochs=max_epochs, animation_interval=animation_interval)\n",
        "\n",
        "    model.fit(X, y, animate=True)\n",
        "\n",
        "    save_choice = input(\"Сохранить анимацию? (y/n, по умолчанию n): \").lower() or \"n\"\n",
        "\n",
        "    ani = model.animate_training(X, y, interval=200)\n",
        "\n",
        "    if save_choice in ['y', 'yes', 'д', 'да']:\n",
        "        try:\n",
        "            filename = f\"kan_training_n{n_neurons}_p{num_control_points}_e{max_epochs}_i{animation_interval}.mp4\"\n",
        "            print(f\"Сохранение анимации как '{filename}'\")\n",
        "            ani.save(filename, writer='ffmpeg')\n",
        "            print(f\"Анимация сохранена!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка: {e}\")\n",
        "            print(\"Анимация будет показана без сохранения.\")\n",
        "\n",
        "    globals()['current_animation'] = ani\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"РЕЗУЛЬТАТЫ:\")\n",
        "    if model.training_history:\n",
        "        mse_values = [frame.get('mse') for frame in model.training_history if frame.get('mse') is not None]\n",
        "        if mse_values:\n",
        "            # Вычисление R² для последней эпохи\n",
        "            y_true = y  # Истинные значения\n",
        "            y_pred = model.predict(X)  # Предсказанные значения\n",
        "            ss_res = np.sum((y_true - y_pred.flatten()) ** 2)\n",
        "            ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "            r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
        "\n",
        "            print(f\"  - Кадров: {len(model.training_history)}\")\n",
        "            print(f\"  - Начальная MSE: {mse_values[0]:.6f}\")\n",
        "            print(f\"  - Финальная MSE: {mse_values[-1]:.6f}\")\n",
        "            improvement = ((mse_values[0] - mse_values[-1]) / mse_values[0]) * 100\n",
        "            print(f\"  - Улучшение MSE: {improvement:.2f}%\")\n",
        "            print(f\"  - Коэффициент детерминации R²: {r2:.4f}\")\n",
        "    print(\"=\" * 50)\n"
      ],
      "metadata": {
        "id": "yOOg_0bVuXCR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Главная функция для запуска демонстраций KAN\n",
        "    \"\"\"\n",
        "    print(\"==== ДЕМОНСТРАЦИИ СЕТЕЙ КОЛМОГОРОВА-АРНОЛЬДА (KAN) ====\")\n",
        "\n",
        "    print(\"\\nВыберите демонстрацию:\")\n",
        "    print(\"1. Формирование B-сплайн функций\")\n",
        "    print(\"2. Процесс обучения\")\n",
        "    print(\"3. Интерактивный процесс обучения\")\n",
        "    print(\"4. Эксперименты с нейронами и точками\")\n",
        "    print(\"5. Сравнение на разных наборах данных\")\n",
        "\n",
        "    try:\n",
        "        choice = int(input(\"\\nВведите число (1–5): \"))\n",
        "        if choice == 1:\n",
        "            print(\"\\n--- ФОРМИРОВАНИЕ B-СПЛАЙНОВ ---\")\n",
        "            print(\"Показывает, как KAN формирует сплайны для аппроксимации.\")\n",
        "            demo_kan_formation()\n",
        "        elif choice == 2:\n",
        "            print(\"\\n--- ПРОЦЕСС ОБУЧЕНИЯ ---\")\n",
        "            print(\"Демонстрирует обучение KAN на синусоиде.\")\n",
        "            demo_kan_training_process()\n",
        "        elif choice == 3:\n",
        "            print(\"\\n--- ИНТЕРАКТИВНОЕ ОБУЧЕНИЕ ---\")\n",
        "            print(\"Позволяет настроить параметры и наблюдать обучение.\")\n",
        "            demo_kan_training_process_interactive()\n",
        "        elif choice == 4:\n",
        "            print(\"\\n--- ЭКСПЕРИМЕНТЫ С ПАРАМЕТРАМИ ---\")\n",
        "            print(\"Исследует влияние нейронов и точек на качество.\")\n",
        "            demo_experiment_neurons_points()\n",
        "        elif choice == 5:\n",
        "            print(\"\\n--- СРАВНЕНИЕ НАБОРА ДАННЫХ ---\")\n",
        "            print(\"Показывает работу KAN на разных функциях.\")\n",
        "            demo_dataset_comparison()\n",
        "        else:\n",
        "            print(\"Выберите число от 1 до 5.\")\n",
        "    except ValueError:\n",
        "        print(\"Введите целое число от 1 до 5.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BbzwwzvaudZ-",
        "outputId": "76293156-cfce-43e6-9ff1-475f928db161"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== ДЕМОНСТРАЦИИ СЕТЕЙ КОЛМОГОРОВА-АРНОЛЬДА (KAN) ====\n",
            "\n",
            "Выберите демонстрацию:\n",
            "1. Формирование B-сплайн функций\n",
            "2. Процесс обучения\n",
            "3. Интерактивный процесс обучения\n",
            "4. Эксперименты с нейронами и точками\n",
            "5. Сравнение на разных наборах данных\n",
            "\n",
            "Введите число (1–5): 5\n",
            "\n",
            "--- СРАВНЕНИЕ НАБОРА ДАННЫХ ---\n",
            "Показывает работу KAN на разных функциях.\n",
            "======================================================================\n",
            "СРАВНЕНИЕ РЕЗУЛЬТАТОВ KAN НА РАЗНЫХ НАБОРАХ ДАННЫХ\n",
            "======================================================================\n",
            "\n",
            "ЦЕЛЬ ЭКСПЕРИМЕНТА:\n",
            "Оценить универсальность KAN на разных типах функций.\n",
            "\n",
            "УСЛОВИЯ ЭКСПЕРИМЕНТА:\n",
            "• Количество образцов: 200\n",
            "• Уровень шума: 0.1\n",
            "• Разделение: 70% обучение / 30% тестирование\n",
            "• Число нейронов: 7\n",
            "• Контрольные точки: 10\n",
            "\n",
            "ТИПЫ ДАННЫХ:\n",
            "1. SIN - Периодическая функция\n",
            "2. EXP - Гауссова функция\n",
            "3. COMPLEX - Комбинированная функция\n",
            "\n",
            "ОБРАБОТКА НАБОРА ДАННЫХ: SIN\n",
            "  Обучение KAN-сети с 7 нейронами\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a888944eec14>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-a888944eec14>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- СРАВНЕНИЕ НАБОРА ДАННЫХ ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Показывает работу KAN на разных функциях.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mdemo_dataset_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Выберите число от 1 до 5.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-19188f561efa>\u001b[0m in \u001b[0;36mdemo_dataset_comparison\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKANNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neurons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_control_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_control_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Обучение KAN-сети с {n_neurons} нейронами\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-d154d83d84e8>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, epochs, lr, animate, l2_lambda)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         )\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingleton_int\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSingletonInt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtry_solve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_symbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_is_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m from torch.utils._sympy.value_ranges import (\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_sympy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_sympy/symbol.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSymT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mSIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mFLOAT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/enum.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(metacls, cls, bases, classdict, boundary, _simple, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# update classdict with any changes made by __init_subclass__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/enum.py\u001b[0m in \u001b[0;36m__set_name__\u001b[0;34m(self, enum_class, member_name)\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmember_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmember_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menum_member\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;31m# now add to _member_map_ (even aliases)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0menum_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_member_map_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmember_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menum_member\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/enum.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(cls, name, value)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmember_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot reassign member %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}